\documentclass[12pt,a4paper]{amsart}
\usepackage{a4wide}
\usepackage[utf8]{inputenc}
\usepackage[T2A]{fontenc}
\usepackage{graphics,graphicx,epsfig}
\usepackage{amssymb,amsfonts,amsthm,amsmath,mathtext,cite,enumerate,float}
\usepackage[english,russian]{babel}
\usepackage[all]{xy}
\usepackage{morefloats}
\usepackage{pgf}
\usepackage[outputdir={docgraphs/}]{dot2texi}
\usepackage{tikz}
\usepackage{scalefnt}
\usetikzlibrary{shapes,arrows}
\usetikzlibrary{decorations.pathmorphing}

% Comment the following block when compiling this .tex with a saner compiler than texlive.
\makeatletter
\def\@settitle{\begin{center}%
    \baselineskip14\p@\relax
    \bfseries
    \@title
  \end{center}%
}
\makeatother

\begin{document}
% Comment the following block when compiling this .tex with a saner compiler than texlive.
\pagestyle{plain}

\title{Алгоритмы порождения существенно нелинейных моделей}
\author{Г.\,И.~Рудой}
\address{Московский физико-технический институт, ФУПМ, каф. <<Интеллектуальные системы>>}
\thanks{Научный руководитель В.\,В.~Стрижов}

\begin{abstract}
  В работе исследуются алгоритмы порождения и отбора существенно нелинейных моделей (символьная регрессия). Полученные модели применяются для восстановления регрессионной зависимости переменной от данных числовых рядов. Описывается представление моделей в виде матриц смежности. В вычислительном эксперименте приводятся результаты для задачи моделирования волатильности опционов.
\end{abstract}

\maketitle

\section{Введение}

Существует ряд методов, предназначенных для решения задачи восстановления
регрессии по набору измеренных данных. Некоторые из этих методов, такие,
как нейронные сети, успешно применяются в ряде предметных областей, но они
не подходят для случаев, когда необходима возможность проинтерпретировать
экспертом полученную модель.

Одним из методов, позволяющих получать интерпретируемые модели, является
символьная регрессия --- процесс, в котором измеренные данные приближаются
некоторой математической формулой, например $ \sin x^2 + 2x $ или
$\log x - \frac{e^x}{x} $. Одна из возможных реализаций этого процесса
предложена John Koza \cite{Koza1998GP} \cite{Koza1998Intro}, использовавшим
эволюционные алгоритмы для реализации символьной регрессии. Ivan Zelinka
предложил дальнейшее развитие этой идеи \cite{Zelinka2008}, получившее
название Analytic Programming.

Среди возможных путей улучшения качества символьной регрессии --- анализ
информативности различных признаков. Например, в ходе работы генетического
алгоритма можно выявлять, какие из параметров слабо влияют на качество
получающейся формулы, и либо убирать их совсем, либо обеспечивать
неслучайность мутаций и кроссовера с целью замены этих параметров на
(возможно) более информативные.

\bibliographystyle{unsrt}
\extrasrussian
\bibliography{bibliography}

\end{document}
