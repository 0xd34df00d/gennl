\documentclass[12pt,a4paper]{amsart}
\usepackage{a4wide}
\usepackage[utf8]{inputenc}
\usepackage[T2A]{fontenc}
\usepackage{graphics,graphicx,epsfig}
\usepackage{amssymb,amsfonts,amsthm,amsmath,mathtext,cite,enumerate,float}
\usepackage[english,russian]{babel}
\usepackage[all]{xy}
\usepackage{morefloats}
\usepackage{pgf}
\usepackage[debug,outputdir={docgraphs/}]{dot2texi}
\usepackage{tikz}
\usepackage{scalefnt}
\usetikzlibrary{shapes,arrows}
\usetikzlibrary{decorations.pathmorphing}

% Comment the following block when compiling this .tex with a saner compiler than texlive.
\makeatletter
\def\@settitle{\begin{center}%
    \baselineskip14\p@\relax
    \bfseries
    \@title
  \end{center}%
}
\makeatother

\newtheorem{algo}{Алгоритм}
\newtheorem{stat}{Утверждение}

\begin{document}
% Comment the following block when compiling this .tex with a saner compiler than texlive.
\pagestyle{plain}

\title{Алгоритмы порождения допустимых суперпозиций существенно нелинейных моделей}
\author{Г.\,И.~Рудой}
\address{Московский физико-технический институт, ФУПМ, каф. <<Интеллектуальные системы>>}
\thanks{Научный руководитель В.\,В.~Стрижов}

\begin{abstract}
  При восстановлении нелинейной регрессии предлагается рассмотреть набор
  индуктивно порожденных моделей с целью выбора оптимальной модели. В работе
  исследуются индуктивные алгоритмы порождения допустимых существенно
  нелинейных моделей. Предлагается алгоритм, порождающий все возможные
  суперпозиции заданной сложности за конечное число шагов. В вычислительном
  эксперименте приводятся результаты для задачи моделирования волатильности
  опционов.
\end{abstract}
\keywords{Символьная регрессия, индуктивное порождение нелинейных моделей}

\maketitle

\section{Введение}

В ряде приложений \cite{Barmpalexis201175} \cite{Shi:2011:CRM}
\cite{DOI:10.1504/IJCENT.2010.038358} возникает задача восстановления
регрессии по набору измеренных данных с условием возможности проинтерпретировать
полученные данные экспертом.

Одним из методов, позволяющих получать интерпретируемые модели, является
символьная регрессия \cite{davidson:2000:snrea} \cite{reference/ml/X10vc},
в ходе которой измеренные данные приближаются
некоторой математической формулой, например $ \sin x^2 + 2x $ или
$\log x - \frac{e^x}{x} $. Одна из возможных реализаций этого метода
предложена Джоном Коза \cite{Koza1998GP} \cite{Koza1998Intro}, использовавшим
эволюционные алгоритмы для реализации символьной регрессии. Иван Зелинка
предложил дальнейшее развитие этой идеи \cite{Zelinka2008}, получившее
название аналитического программирования.

Фактически, получаемая математическая формула является математической моделью
\cite{Pavlovsky2000} исследуемого процесса или явления, то есть, это
математическое отношение, описывающее основные закономерности, присущие этому
явлению.

Алгоритм построения требуемой математической модели выглядит следующим образом:
дан набор примитивных функций, из которых можно строить различные формулы
(например, степенная функция, $+$, $\sin$, $\tan$). Начальный набор формул
строится либо произвольным образом, либо на базе некоторых предположений
эксперта. Затем на каждом шаге производится оценка каждой из формул согласно
функции ошибки либо другого \footnote{Сходу не нашел публикаций на тему
использования других функционалов. Похоже, у Владиславлевой что-то было, но
пока не могу сослаться на что-то конкретное.} функционала качества. На базе
этой оценки у некоторой части формул случайным образом заменяется одна элементарная
функция на другую (например, $\sin$ на $\cos$ или $+$ на $\times$), а у некоторой
другой части происходит взаимный попарный обмен подвыражениями в формулах.

Среди возможных путей улучшения качества символьной регрессии --- анализ
информативности различных признаков. Например, в ходе работы эволюционного
алгоритма можно выявлять, какие из параметров слабо влияют на качество
получающейся формулы, и либо убирать их совсем, либо обеспечивать
неслучайность замены элементарных функций или обмена поддеревьев с целью
замены этих параметров на другие в предположении, что они, возможно,
окажутся более информативными.

Целью данной работы является теоретическое обоснование алгоритмов индуктивного
порождения моделей и анализ этих алгоритмов.

Другим вопросом, возникающим при применении подобных эволюционных алгоритмов,
является их принципиальная теоретическая корректность: способен ли вообще
такой алгоритм породить искомую формулу.

В части 2 данной работы формально поставлена задача построения алгоритма
индуктивного порождения моделей. Затем, в части 3 строится искомый алгоритм
для частного случая непараметризованных моделей и доказывается его корректность,
а затем алгоритм обобщается на случай моделей, имеющих параметры. В части 4
описываются вспомогательные технические приемы, использованные в практическом
алгоритме порождения моделей, описанном в части 5.

\section{Постановка задачи}

\subsection{Алгоритмическая часть}

Пусть дан набор $(\mathbf{x_i}, y_i) \mid i \in \{1, \dots, N\}, \mathbf{x_i} \in R^n, y_i \in R$.
Предполагается, что $\mathbf{y} \in \mathcal{N}$ \footnote{А правда, зачем?}.

Требуется построить аналитическую функцию $f : R^n \rightarrow R$ из заданного
множества элементарных функций $G$ и доставляющую минимум некоторому функционалу
ошибки.

\subsection{Теоретическая часть}

Пусть $G = \{ g_1, \dots, g_{n_g} \}$ --- множество данных примитивных функций.
Требуется:

\begin{itemize}
  \item Построить алгоритм $\mathfrak{A}$, за конечное число итераций
	порождающий любую конечную суперпозицию, являющуюся суперпозицией данных
	примитивных функций.
  \item Указать способ проверки изоморфности двух суперпозиций.
\end{itemize}

\section{Пути решения задачи: теоретическая часть}

Условимся считать, что каждой суперпозиции $f$ сопоставлено дерево $\Gamma_f$,
эквивалентное этой суперпозиции и строящееся следующим образом:

\begin{itemize}
  \item В вершинах дерева находятся соответствующие примитивные функции.
  \item Число дочерних вершин у некоторой вершины равно арности соответствующей
	функции, а их порядок (в смысле обхода в глубину) соответствует порядку
	аргументов соответствующей функции.
  \item В листьях дерева находятся свободные переменные.
  \item Порядок вершин в смысле уровня относительно корня дерева определяет
	порядок вычисления примитивных функций: дерево вычисляется снизу вверх.
	То есть, сначала подставляются конкретные значения свободных переменных,
	затем вычисляются значения в вершинах, все дочерние вершины которых ---
	свободные переменные, и так далее до тех пор, пока не останется
	единственная вершина, бывшая корнем дерева, содержащая результат выражения.
\end{itemize}

Таким образом, вычисление значения суперпозиции в некоторой точке эквивалентно
подстановке соответствующих значений свободных переменных в граф выражения.

Для примера рассмотрим граф, соответствующий суперпозиции
$\sin (\ln x_1) + \frac{x_2^3}{2}$:

\begin{tikzpicture}
\scalefont{2}
\tikzstyle{n} = [draw, inner sep=2pt, fill=red!20]
\begin{dot2tex}[dot,options=-tmath,scale=0.5]
  digraph G1 {
	node [shape="circle",style="n"];
	
	Plus [label="\bullet + \bullet"];
	Sin [label="\sin \bullet];
	Ln [label="\ln \bullet"];
	X1 [label="x_1"];
	Frac [label="\div"];
	Pow [label="\bullet^{\bullet}"];
	X2 [label="x_2"];
	N3 [label="3"];
	N2 [label="2"];

	Plus -> Sin;
	Sin -> Ln;
	Ln -> X1;

	Plus -> Frac;
	Frac -> Pow;
	Frac -> N2;

	Pow -> X2;
	Pow -> N3;
  }
\end{dot2tex}
\end{tikzpicture}

\subsection{Алгоритм порождения суперпозиций}

Итак, пусть дано множество примитивных функций $G = \{ g_1, \dots, g_{n_g} \}$ и
множество свободных переменных $X = \{ x_1, \dots, x_{n_x} \}$. Сначала
опишем итеративный алгоритм, позволяющий за конечное число итераций
построить суперпозицию произвольной наперед заданной длины. Для удобства
будем исходить из предположения, что множество $G$ состоит только из унарных
и бинарных функций, и разделим его соответствующим образом на два
подмножества:
$G = G_b \cup G_u \mid G_b = \{ g_{b_1}, \dots, g_{b_k} \}, G_u = \{ g_{u_1}, \dots, g_{u_l} \}$,
где $G_b$ --- множество всех бинарных функций, а $G_u$ --- множество всех
унарных функций из $G$. Потребуем также наличия $id$ в $G_b$.

\begin{algo}
  Алгоритм $\mathfrak{A}$ итеративного порождения суперпозиций.
  \begin{enumerate}
	\item Инициализируем вспомогательное множество $\mathcal{I}_f = \{ (x, 0) \mid x \in X \}$.
	\item Инициализируем множество $\mathcal{F}_0 = X$.
	\item Для множества $\mathcal{F}_i$ построим вспомогательное множество $U_i$,
	  состоящее из результатов применения функций из $G_u$ к элементам $\mathcal{F}_i$:
	  \[
	  U_i = \{ g_u \circ f \mid g_u \in G_u, f \in \mathcal{F}_i \}
	  \]
	\item Аналогичным образом построим вспомогательное множество $B_i$ для
	  бинарных функций:
	  \[
	  B_i = \{ g_b \circ (f, h) \mid g_b \in G_b, f, h \in \mathcal{F}A_i \}
	  \]
	\item Обозначим $\mathcal{F}_{i+1} = \mathcal{F}_i \cup U_i \cup B_i$.
	\item Для каждой суперпозиции $f$ из $\mathcal{F}_{i+1}$ добавим пару
	  $(f, i+1)$ в множество $\mathcal{I}_f$, если суперпозиция $f$ еще там
	  не присутствует.
	\item Перейдем к следующей итерации. 
  \end{enumerate}
\end{algo}

Тогда $\mathcal{F} = \cup_0^\infty \mathcal{F}_i$ --- множество всех
возможных суперпозиций конечной длины, построимых из данного множества
примитивных функций.

Вспомогательное множество $\mathcal{I}_f$ позволяет запоминать, на какой
итерации была впервые встречена данная суперпозиция. Это необходимо, так
как каждая суперпозиция, впервые порожденная на $i$-ой итерации, будет
порождена еще раз и на любой итерации после $i$.

Алгоритм $\mathfrak{A}$ очевидным образом обобщается на множество $G$,
содержащее функции произвольной (но имеющей конечный верхний предел)
арности. Действительно, для такого обобщения достаточно строить аналогичным
образом вспомогательные множества для этих функций.

\begin{stat}
  Алгоритм $\mathfrak{A}$ корректен: любую конечную суперпозицию он
  действительно породит за конечное число шагов.
\end{stat}
\begin{proof}
  Чтобы убедиться в этом, найдем номер итерации, на котором будет порождена
  некоторая произвольная конечная суперпозиция $f$. Для этого достаточно
  представить суперпозицию $f$ в виде соответствующего графа $\Gamma_f$
  и рекурсивно пройти от вершин к листьям, составляя цепочку соотношений
  на номера итераций по следующим правилам:

  \begin{itemize}
	\item Если вершина, полученная на $i$-ой итерации —-- унарная функция,
	  то это функция от выражения, полученного на $(i-1)$-ой итерации.
	\item Если вершина, полученная на $i$-ой шаге --- бинарная функция, то
	  это функция от двух выражений, как минимум одно из которых получено
	  на $(i-1)$-ой итерации, а другое --- на $(i-1)$-ой или ранее.
	\item Если это узел со свободной переменной, то он получен на нулевой
	  итерации.
  \end{itemize}

  При помощи этой цепочки соотношений можно получить номер итерации, на
  которой суперпозиция $f$ была порождена.
  
  Иными словами, для любой суперпозиции мы можем указать конкретный номер
  итерации, на котором она будет получена, что и требовалось.
\end{proof}

Заметим, что алгоритм в таком виде не позволяет получать выражения для
численных коэффициентов. Покажем, однако, на примере конструирования
множеств $U_i$ и $B_i$, как исходный алгоритм может быть расширен с учетом
таких коэффициентов:

\[
U_i = { g_u \circ (\alpha f + \beta) }
\]
\[
B_i = { g_b \circ (\alpha f + \beta, \psi h + \phi) }
\]

Здесь коэффициенты $\alpha, \beta$ зависят только от комбинации $g_u, f$ (или
$g_b, f, h$ для $\alpha, \beta, \psi, \phi$). Соответственно, для упрощения
их индексы опущены.

Иными словами, мы неявно предполагаем, что каждая суперпозиция из предыдущих
итераций входит в следующую, будучи умноженной на некоторой коэффициент и с
константной поправкой.

Очевидно, при таком добавлении коэффициентов $\alpha, \beta, \psi, \phi$
мы не изменяем мощности получившегося множества суперпозиций, поэтому
алгоритм и выводы из него остаются корректны. В частности, исходный алгоритм
является частным случаем данного при
$\alpha = \psi = 1, \beta = \phi = 0$.

$\alpha, \beta, \psi, \phi$ являются параметрами модели. В практических
приложениях можно оптимизировать значения этих параметров у получившихся
суперпозиций, например, алгоритмом Левенберга-Марквардта
\cite{Marquardt1963Algorithm} \cite{more:78}.

Заметим так же, что такая модификация алгоритма позволяет нам получить единицу,
например, для построения суперпозиций типа $\frac{1}{x}$:
$1 = \alpha\ id\ x + \beta \mid \alpha = 0, \beta = 1$.

Отдельно подчеркнем, что численные коэффициенты у различных суперпозиций
различны. Однако, так как на разных итерациях алгоритма мы можем получить,
вообще говоря, одну и ту же суперпозицию с точностью до этих коэффициентов,
их необходимо не учитывать при тестировании различных суперпозиций на
равенство.

Кроме того, опять же, заметим, что и этот алгоритм очевидным образом
обобщается на случай множества $G$, содержащего функции произвольной арности.

\subsection{Бесконечные суперпозиции}

В предложенных ранее методах\cite{Zelinka2008} построения суперпозиций
необходимо было самостоятельно следить за тем, чтобы в ходе работы алгоритма
не возникало <<зацикленных>> суперпозиций типа $f(x, y) = g (f(x, y), x, y)$.
Заметим, что в предложенном алгоритме такие суперпозиции не могут возникнуть
по построению.

\subsection{Множество допустимых суперпозиций}

Предложенный выше алгоритм позволяет получить действительно все возможные
суперпозиции, однако, не все они будут пригодны в практических приложениях:
например, $\ln x$ имеет смысл только при $x > 0$, а $\frac{x}{0}$ не имеет
смысла вообще никогда. Выражения типа $\frac{x}{\sin x}$ имеют смысл только
при $x \neq \pi k$.

Таким образом, необходимо введение понятия множества \emph{допустимых}
суперпозиций --- то есть, таких суперпозиций, которые в условиях некоторой
задачи корректны.

Одним из способов построения только допустимых суперпозиций является
модификация предложенного алгоритма таким образом, чтобы отслеживать
совместность областей определения и областей значения соответствующих
функций в ходе построения суперпозиций. Для свободных переменных это будет,
в свою очередь, означать необходимость задания областей значений пользователем
при решении конкретных задач.

Заметим, что, хотя теоретически возможно выводить допустимость выражений
вида $\frac{x}{\sin x}$ исходя из заданных условий на свободную переменную
(например, что $x \in (\frac{\pi}{4}, \frac{\pi}{2})$), в общем случае это
потребует решения неравенств в общем виде, что вычислительно неэффективно
\footnote{А было бы вычислительно эффективно --- все равно, похоже, было бы
NP-сложной задачей}.

\subsection{Множество <<минимальных>> суперпозиций}

В ходе работы алгоритма могут возникать суперпозиции вида $x + x$ и $2x$,
и хотя эти выражения эквивалентны, они представляются различными формулами.
Аналогично $x + y$ и $y + x$, отличающиеся порядком следования слагаемых.
Таким образом, необходим способ нормализации суперпозиций.

Во-первых, необходимо обеспечивать одинаковый порядок следования операндов,
например, упорядочивая их каким-либо образом у коммутирующих бинарных функций.

Во-вторых, необходимо иметь набор правил, позволяющих проверить равенство
$x + x$ и $2x$. Иными словами, необходимо иметь набор связей между различными
функциями из множества данных примитивных функций. Заметим, что в общем
случае эта задача требует введения значительного числа правил и по определению
сводится к последовательному переборному их применению к различным
подвыражениям суперпозиции.

В связи с этим может оказаться более эффективным иной подход к сравнению
суперпозиций: так как по условию практической задачи значения искомой функции
даны в конечном числе точек, то для проверки на равенство достаточно вычислить
получившиеся суперпозиции в этих точках и сравнить их.\footnote{Кстати, может,
можно придумать какой-нибудь оптимальный алгоритм поиска расходящихся точек?
Ну или эвристику хотя бы, позволяющую перебирать данные точки не в лоб, а
более целенаправленно и позволяя находить точки, в которых значения различаются,
более быстро.}

Другим способом, позволяющим избежать разрастания количества правил, может
являться использование только <<независимых>> функций. Например, $\sin$ и
$\cos$ связаны известным тригонометрическим соотношением с точностью до знака,
а значит, $\sin$ и $\tan = \frac{\sin}{\cos}$ также связаны, как и ряд прочих
тригонометрических функций, поэтому предлагается среди примитивных функций
оставить лишь $\sin$ и стандартные арифметические действия для вывода прочих
тригонометрических функций через соответствующие соотношения.

Однако, можно заметить два часто встречающихся шаблона правил, связывающих
различные функции:
\begin{itemize}
  \item Для унарных функций это $f \circ g = h$ (например,
	$\ln \circ \exp = id$).
  \item Для бинарных функций это $ f (x, g (x, i)) = g (x, s (i)) $.
	Например, $x + xi = x(i+1)$: здесь $f = (+), g = (\times), s(i) = i + 1$.
\end{itemize}

В практических приложениях видится целесообразным использование набора правил
такого вида вкупе с использованием только <<независимых>> тригонометрических
функций, то есть, по факту, какой-нибудь одной из них и еще одной обратной.

\section{Алгоритм Левенберга-Марквардта и мультистарт}

Алгоритм Левенберга-Марквардта $\mathfrak{LM}$ предназначен для решения
задачи минимизации функции, представляющей из себя сумму квадратичных членов.
В частности, он используется для оптимизации параметров нелинейных регрессионных
моделей в предположении, что в качестве критерия оптимизации используется
среднеквадратичная ошибка модели на обучающей выборке:

\[
S(\mathbf{\beta}) = \sum_{i=1}{m} [y_i - f(\mathbf{x_i}, \mathbf{\beta})]^2 \to \min,
\]
где $\mathbf{\beta}$ --- вектор параметров модели (суперпозиции) $f$.

$\mathfrak{LM}$ может рассматриваться как комбинация метода Гаусса-Ньютона и
метода градиентного спуска.\footnote{Доописать алгоритм.}

Как и всякий подобный алгоритм оптимизации, $\mathfrak{LM}$ находит лишь
локальный минимум. Для решения этой проблемы применяется метод \emph{мультистарта}:
случайным образом задается несколько начальных приближений, и для каждого из
них запускается $\mathfrak{LM}$. Если найдено несколько различных локальных
минимумов, то выбирается тот из них, в котором значение $S(\mathbf{\beta})$
меньше всего.

\section{Вычислительный эксперимент}

\subsection{Алгоритм}

Несмотря на то, что указанный ранее итеративный алгоритм порождения
суперпозиций позволяет получить, в принципе, произвольную суперпозицию,
для практических применений он непригоден, как и любой алгоритм, реализующий
полный перебор, в связи с чрезмерной вычислительной сложностью. Вместо него
можно использовать стохастические алгоритмы и ряд эвристик, позволяющих на
практике получать за приемлемое время результаты, удовлетворяющие заранее
заданным условиям <<достаточной пригодности>>.

В данной работе предлагается следующий алгоритм:

\begin{algo}
  Алгоритм стохастического порождения суперпозиций.

  Вход:
  \begin{enumerate}
	\item Множество примитивных функций.
	\item Множество точек обучающей выборки.
	\item $N_{max}$ --- максимальное число одновременно рассматриваемых
	  суперпозиций.
	\item $I_{max}$ --- максимальное число итераций алгоритма.
	\item $F_{min}$ --- минимальная приспособленность суперпозиций.
  \end{enumerate}

  \begin{enumerate}
	\item Инициализируется начальный массив суперпозиций случайным образом.
	\item Оптимизируются параметры суперпозиций алгоритмом $\mathfrak{LM}$.
	\item Для каждой еще не оцененной суперпозиции $f$ рассчитывается значение
	  функции ошибки $S_f$ на обучающей выборке, и ставится в соответствие
	  значение $F_f$, характеризующее <<приспособленность>> суперпозиции $f$:
	  $F_f = \frac{1}{1 + S_f}$. Таким образом, чем лучше результаты суперпозиции,
	  тем ближе значение ее приспособленности к $1$, и, наоборот, чем хуже ---
	  тем ближе к $0$. Если данная суперпозиция точно описывает данные, то
	  значение ее приспособленности в точности равно единице.
	\item Массив суперпозиций сортируется согласно их приспособленности.
	\item Наименее приспособленные суперпозиции удаляются из массива до тех
	  пор, пока его размер не станет равен $N_max$.
	\item Отбирается некоторая часть наименее приспособленных суперпозиций.
	  У этой части происходит случайная замена одной функции или свободной
	  переменной на другую. Замена такова, чтобы сохранилась структура
	  суперпозиции, а именно --- в случае замены функции сохраняется арность,
	  а свободная переменная заменяется только на другую свободную переменную.
	  При этом исходные суперпозиции сохраняются в множестве.
	\item Повторяются шаги $3-4$.
	\item Производится случайный обмен поддеревьями наиболее приспособленных
	  суперпозиций. При этом исходные суперпозиции сохраняются в массиве.
	\item Повторяются шаги $3-4$.
	\item Проверяются условия останова: если либо число итераций больше
	  $I_{max}$, либо в массиве есть хотя бы одна суперпозиция с
	  приспособленностью больше, чем $F_{min}$, то алгоритм останавливается,
	  и результатом является наиболее приспособленная суперпозиция, иначе
	  переход к шагу $2$.
  \end{enumerate}
\end{algo}

\bibliographystyle{unsrt}
\extrasrussian
\bibliography{bibliography}

\end{document}
